<html>

<head>
    <title>PSYC 684 Project Hennessy McLaughlin Mittal</title>
</head>

<body style="margin: 5% 25% 10% 25%">
    <h1 style="text-align: center;">Working Towards Explainable Detection of Alzheimer’s Disease using Phoneme Discretized Saliency Maps and eGeMAPS Feature Extraction</h1>
    <h2 style="text-align: center;">PSYC 684 Project Page</h2>
    <p style="text-align: center;">Harry Hennessy, Jack McLaughlin, and Prerit Mittal</p>

    <h3 style="text-align: center;">Abstract</h3>
    <p>Speech has the ability to convey deep insights about the state of the speaker, in terms of both emotion and health. Several projects have elucidated this
link, analyzing speech to predict emotions or health. Recent advances have been made in this field, specifically in determining which fragments of
speech are most identifying. Gupta et al.’s Phoneme Discretized Saliency Maps for Explainable Detection of AI-Generated Voice uses the titular Phoneme Discretized 
Saliency Maps, or PDSMs, to determine identifiers of AI generated speech, a useful tool to combat disinformation in the modern age. However,
this approach has not been applied for more classical speech classification problems, such as the detection of Alzheimer’s Disease in patients. Using 
the Alzheimer’s Dementia Recognition through Spontaneous Speech, or ADReSS dataset, this paper aims to use Gupta et al.’s method and other
methods, including the feature set eGeMAPS, to determine which areas of speech are most indicative of the disease, comparing these results to each
other and examining their validity. By finding these most indicative pieces of speech, it may be possible to better understand and detect the disease in
advance and assist patients more proactively.</p>

    <h3 style="text-align: center;">Download</h3>
    <a style="text-align: center;" href="https://drive.google.com/drive/folders/1ukxskB_IQNTKc_ZYqpLWbJHVQWK-vVE4?usp=drive_link">Link to Finalized Project Folder (Updated 12/9)</a>

</body>

</html>
