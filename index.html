<html>
<head>
  <title>PSYC 684 Project Hennessy McLaughlin Mittal</title>
</head>
<body>
  <h1>PSYC 684 Project Page (WIP)</h1>
  <h2>Explainable Detection of Alzheimer's</h2>
  <p>Harry Hennessy, Jack McLaughlin, and Prerit Mittal</p>
  <p>We will be building off the work of the following papers:</p>
  <ul>
    <li><a href="https://luzs.gitlab.io/adress">Alzheimer's Dementia Recognition through Spontaneous Speech The ADReSS Challenge</a></li>
    <li><a href="https://mycourses.rit.edu/d2l/le/content/1166569/viewContent/11016134/View">A Comparative Analysis of Federated Learning for Speech-Based Cognitive Decline Detection</a></li>
    <li><a href="https://mycourses.rit.edu/d2l/le/content/1166569/viewContent/11016132/View">A New Approach to Voice Authenticity</a></li>
    <li><a href="https://mycourses.rit.edu/d2l/le/content/1166569/viewContent/11016118/View">Phoneme Discretized Saliency Maps for Explainable Detection of
AI-Generated Voice</a></li>
  </ul>

  <h3>Abstract</h3>
  <p style="margin:15%">Speech has the ability to convey deep insights about the state of the speaker, through both emotion and health. Several projects have elucidated this link, analyzing speech to predict emotions or health. Recent advances have been made in this field, specifically in determining which fragments of speech are most identifying. Gupta et al.’s Phoneme Discretized Saliency Maps for Explainable Detection of AI-Generated Voice uses the titular Phenome Discretized Saliency Maps, or PDSMs, to determine identifiers of AI generated speech, a useful tool to combat disinformation in the modern age. However, this approach has not been applied for more classical speech classification problems, such as the detection of Alzheimer’s in patients. Using the Alzheimer’s Dementia Recognition through Spontaneous Speech, or ADReSS dataset, this paper aims to use Gupta et al.’s method and other methods to determine which areas of speech are most indicative of the disease, comparing these results to identifiers of other aspects of speech, such as emotion or realness. By finding these most indicative pieces of speech, it may be possible to better detect the disease in advance and assist patients more proactively.</p>

  <h3>References</h3>
  <ol>
    <li>Gupta, S., Ravanelli, M., Germain, P., Subakan, C. (2024) Phoneme Discretized Saliency Maps for Explainable Detection of AI-Generated Voice. Proc. Interspeech 2024, 3295-3299, doi: 10.21437/Interspeech.2024-632</li>
    <li>Kalabakov, S., Gonzalez-Machorro, M., Eyben, F., Schuller, B. W., & Arnrich, B. (2024). A Comparative Analysis of Federated Learning for Speech-Based Cognitive Decline Detection. Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, 2455-2459. https://doi.org/10.21437/Interspeech.2024-996</li>
    <li>Müller, N.M., Kawa, P., Hu, S., Neu, M., Williams, J., Sperl, P., Böttinger, K. (2024) A New Approach to Voice Authenticity. Proc. Interspeech 2024, 2245-2249, doi: 10.21437/Interspeech.2024-31</li>
  </ol>
  
  
</body>

</html>
